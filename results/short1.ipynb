{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load process_cat\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pro_cat(targets, observed, estimated, test):\n",
    "\n",
    "    date_calc_re_ob = estimated.set_index('date_forecast')['date_calc'].resample('H').first().to_frame()\n",
    "    date_calc_re_te = test.set_index('date_forecast')['date_calc'].resample('H').first().to_frame()\n",
    "\n",
    "    # resample observed, estimated, and test data to 1 hour\n",
    "    observed_re = observed.set_index('date_forecast').resample('H').mean(numeric_only=1).dropna(how='all').reset_index()\n",
    "    estimated_re = estimated.set_index('date_forecast').resample('H').mean(numeric_only=1).dropna(how='all').reset_index()\n",
    "    test_re = test.set_index('date_forecast').resample('H').mean(numeric_only=1).dropna(how='all').reset_index()\n",
    "\n",
    "    estimated_re = estimated_re.merge(date_calc_re_ob, left_on='date_forecast', right_index=True)\n",
    "    test_re = test_re.merge(date_calc_re_te, left_on='date_forecast', right_index=True)\n",
    "\n",
    "    # dropped due to redundancy, inconsistency, lack of relevance or for further processing\n",
    "    columns_to_drop = ['wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'wind_speed_u_10m:ms', 'snow_drift:idx', 'snow_density:kgm3', 'elevation:m']\n",
    "    test_re = test_re.drop(columns=columns_to_drop)\n",
    "    observed_re = observed_re.drop(columns=columns_to_drop)\n",
    "    estimated_re = estimated_re.drop(columns=columns_to_drop)\n",
    "\n",
    "    # fuse observed and estimated data\n",
    "    weather_data, test_re = delta(observed_re, estimated_re, test_re)\n",
    "    # fuse with target values\n",
    "    fused = pd.merge(targets, weather_data, how='inner', left_on='time', right_on='date_forecast')\n",
    "    fused = clock_feat(fused, 'time')\n",
    "    test_re = clock_feat(test_re, 'date_forecast')\n",
    "\n",
    "    fused = fused[fused['pv_measurement'] != 0]\n",
    "    fused = consec(fused)\n",
    "\n",
    "    # calculate the difference\n",
    "    fused['diff'] = fused['pv_measurement'].diff().fillna(0)\n",
    "    # create an indicator for constant stretches\n",
    "    fused['constant'] = (fused['diff'] == 0).astype(int)\n",
    "    # use the indicator to mark stretches\n",
    "    fused['block'] = (fused['constant'].diff() != 0).astype(int).cumsum()\n",
    "    # get size of each constant block\n",
    "    block_sizes = fused.groupby('block')['constant'].sum()\n",
    "    # identify blocks that are constant for more than 2 consecutive time points\n",
    "    constant_blocks = block_sizes[block_sizes > 2].index\n",
    "    # remove the constant stretches\n",
    "    filtered = fused[~fused['block'].isin(constant_blocks)]\n",
    "\n",
    "    # clean auxillary\n",
    "    trgts = filtered[['time', 'pv_measurement']]\n",
    "    filtered = filtered.drop(columns=['diff', 'constant', 'block'])\n",
    "\n",
    "    # drop non-feature columns\n",
    "    filtered = filtered.drop(columns=['time', 'date_forecast', 'pv_measurement','date_calc'])\n",
    "    test_re = test_re.drop(columns=['date_forecast','date_calc'])\n",
    "\n",
    "    return filtered, test_re, trgts\n",
    "\n",
    "\n",
    "def clock_feat(df, col):\n",
    "    # use as features in the model\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    df['hour'] = df[col].dt.hour\n",
    "    df['month'] = df[col].dt.month\n",
    "    df['year'] = df[col].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def delta(observed, estimated, test):\n",
    "    # create time-delta for estimated data\n",
    "    estimated['time_delta'] = (estimated['date_calc'] - estimated['date_forecast']).dt.total_seconds() / 3600\n",
    "    observed['time_delta'] = 0  # since observed data is not forecasting ahead\n",
    "    test['time_delta'] = (test['date_calc'] - test['date_forecast']).dt.total_seconds() / 3600\n",
    "\n",
    "    # indicator variable for estimated data\n",
    "    estimated['is_estimated'] = 1\n",
    "    observed['is_estimated'] = 0\n",
    "    test['is_estimated'] = 1\n",
    "    df = pd.concat([observed, estimated], axis=0).sort_values(by='date_forecast')\n",
    "\n",
    "    return df, test\n",
    "\n",
    "\n",
    "def consec(df, threshold=4, threshold_zerko=15, threshold_zerko_no_rad=20):\n",
    "    # attempt to remove consecutive measurements, given the specified threshold\n",
    "    mask = (df['pv_measurement'] != df['pv_measurement'].shift(1)).cumsum()\n",
    "    df['group'] = df.groupby(mask).transform('count')['pv_measurement']\n",
    "\n",
    "    df[\"first_group\"] = False\n",
    "    df['first_group'] = df['group'] != df['group'].shift(1)\n",
    "\n",
    "    # masks to remove rows\n",
    "    mask_non_zerko = (df['group'] >= threshold) & (\n",
    "        df[\"pv_measurement\"] > 0) & (df[\"first_group\"] == False)\n",
    "\n",
    "    mask_zerko = (df['group'] >= threshold_zerko) & (\n",
    "        df[\"pv_measurement\"] == 0) & (df[\"direct_rad:W\"] > 10)\n",
    "\n",
    "    mask_zerko_no_rad = (df['group'] >= threshold_zerko_no_rad) & (\n",
    "        df[\"pv_measurement\"] == 0) & (df[\"direct_rad:W\"] < 10)\n",
    "    mask = mask_non_zerko | mask_zerko | mask_zerko_no_rad\n",
    "\n",
    "    df = df.loc[~mask]\n",
    "    df = df.drop(columns=[\"group\", \"first_group\", \"direct_rad:W\"])\n",
    "\n",
    "    return df.reset_index(drop=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81595ae6587d4e7da38647b5b5c602d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4151d6203ac64efa85302def4d62af9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbe1498330f4714a53861bd79081983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loc = ['A', 'B', 'C']\n",
    "#loc = 'A'\n",
    "cat_all = []\n",
    "\n",
    "for loc in loc:\n",
    "    train = pd.read_parquet(f'./data/{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'./data/{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'./data/{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'./data/{loc}/X_test_estimated.parquet')\n",
    "     \n",
    "    X_train_cat, X_test_cat, targets_cat = pro_cat(train, X_train_observed, X_train_estimated, X_test_estimated)\n",
    "    X_test_cat = X_test_cat.drop([\"direct_rad:W\"], axis=1)\n",
    "\n",
    "    feat = ['dew_or_rime:idx' ,'is_in_shadow:idx']\n",
    "\n",
    "    for i in feat:\n",
    "        X_train_cat[i] = X_train_cat[i].astype(int)\n",
    "        X_test_cat[i] = X_test_cat[i].astype(int)\n",
    "\n",
    "    params = {\n",
    "        \"loss_function\": 'MAE',\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"silent\": True,\n",
    "        \"cat_features\": feat,\n",
    "    }\n",
    "\n",
    "    model_cat = cated.CatBoostRegressor(**params)\n",
    "    model_cat.fit(X_train_cat, targets_cat['pv_measurement'], plot=True)\n",
    "\n",
    "    cat_preds = model_cat.predict(X_test_cat)\n",
    "    cat_preds = np.clip(cat_preds, 0, None)\n",
    "    cat_all.append(cat_preds)\n",
    "\n",
    "kot_preds = np.array(cat_all).flatten()\n",
    "df = pd.DataFrame(kot_preds, columns=['prediction'])\n",
    "df['id'] = df.index\n",
    "df = df[['id', 'prediction']]\n",
    "df.to_csv('yet_another_cat.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv('yet_another_cat.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskmana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
